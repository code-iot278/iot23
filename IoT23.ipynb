{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uzym9d_S2nE",
        "outputId": "2d53de79-1739-4c2b-f38a-db88335a2b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKqDNbZuT1_8"
      },
      "source": [
        "# **Enhancing Security in CPS Industry 5.0 Using Lightweight MobileNetV3 with Adaptive Optimization Technique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqDorzutT578"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih-50eqAT02F"
      },
      "source": [
        "# **Gaussian Filter**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "Sn1czpbsUVYk",
        "outputId": "c8c519e4-6410-4e8c-8bf9-f2ca2cf3baa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gaussian filtered CSV file saved as /content/drive/MyDrive/Colab Notebooks/IoT23/gaussian_filtered_output.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4e8d54ef-040b-4169-b596-03f1b5960025\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ts</th>\n",
              "      <th>id.orig_h</th>\n",
              "      <th>duration</th>\n",
              "      <th>orig_bytes</th>\n",
              "      <th>resp_bytes</th>\n",
              "      <th>missed_bytes</th>\n",
              "      <th>orig_pkts</th>\n",
              "      <th>orig_ip_bytes</th>\n",
              "      <th>resp_pkts</th>\n",
              "      <th>...</th>\n",
              "      <th>conn_state_RSTOS0</th>\n",
              "      <th>conn_state_RSTR</th>\n",
              "      <th>conn_state_RSTRH</th>\n",
              "      <th>conn_state_S0</th>\n",
              "      <th>conn_state_S1</th>\n",
              "      <th>conn_state_S2</th>\n",
              "      <th>conn_state_S3</th>\n",
              "      <th>conn_state_SF</th>\n",
              "      <th>conn_state_SH</th>\n",
              "      <th>conn_state_SHR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1540469808</td>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>22.479066</td>\n",
              "      <td>890</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1113</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1540469746</td>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>93.124853</td>\n",
              "      <td>3665</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>4066</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1540469748</td>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>153.482083</td>\n",
              "      <td>6035</td>\n",
              "      <td>89</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>6599</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1540469948</td>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>93.185502</td>\n",
              "      <td>3682</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>4029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1540470174</td>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>20.899232</td>\n",
              "      <td>858</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>958</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e8d54ef-040b-4169-b596-03f1b5960025')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e8d54ef-040b-4169-b596-03f1b5960025 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e8d54ef-040b-4169-b596-03f1b5960025');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb5b86b8-3caf-480b-b181-93b3f897ace8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb5b86b8-3caf-480b-b181-93b3f897ace8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb5b86b8-3caf-480b-b181-93b3f897ace8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Unnamed: 0          ts      id.orig_h    duration  orig_bytes  resp_bytes  \\\n",
              "0           0  1540469808  192.168.1.132   22.479066         890          92   \n",
              "1           1  1540469746  192.168.1.132   93.124853        3665         128   \n",
              "2           2  1540469748  192.168.1.132  153.482083        6035          89   \n",
              "3           3  1540469948  192.168.1.132   93.185502        3682          50   \n",
              "4           4  1540470174  192.168.1.132   20.899232         858          46   \n",
              "\n",
              "   missed_bytes  orig_pkts  orig_ip_bytes  resp_pkts  ...  conn_state_RSTOS0  \\\n",
              "0             0          6           1113          2  ...                  0   \n",
              "1             0         13           4066          1  ...                  0   \n",
              "2             0         19           6599          0  ...                  0   \n",
              "3             0         12           4029          0  ...                  0   \n",
              "4             0          3            958          0  ...                  0   \n",
              "\n",
              "  conn_state_RSTR  conn_state_RSTRH  conn_state_S0  conn_state_S1  \\\n",
              "0               0                 0              0              0   \n",
              "1               0                 0              0              0   \n",
              "2               0                 0              0              0   \n",
              "3               0                 0              0              0   \n",
              "4               0                 0              0              0   \n",
              "\n",
              "   conn_state_S2  conn_state_S3  conn_state_SF  conn_state_SH  conn_state_SHR  \n",
              "0              0              0              0              0               0  \n",
              "1              0              0              0              0               0  \n",
              "2              0              0              0              0               0  \n",
              "3              0              0              0              0               0  \n",
              "4              0              0              0              0               0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "# Load the dataset\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/iot23_combined.csv\"  # Replace with your actual input file\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/gaussian_filtered_output.csv\"\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Apply Gaussian Filtering (assuming numerical data columns)\n",
        "def apply_gaussian_filter(df, sigma=1):\n",
        "    filtered_df = df.copy()\n",
        "    for column in df.select_dtypes(include=[np.number]).columns:\n",
        "        filtered_df[column] = gaussian_filter(df[column], sigma=sigma)\n",
        "    return filtered_df\n",
        "\n",
        "df_filtered = apply_gaussian_filter(df, sigma=1)\n",
        "\n",
        "# Save the Gaussian filtered data to a new CSV file\n",
        "df_filtered.to_csv(output_csv, index=False)\n",
        "print(f\"Gaussian filtered CSV file saved as {output_csv}\")\n",
        "df_filtered.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVTTmmn7U2Lc"
      },
      "source": [
        "# **Mean Imputation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "7eXCRsofUmPV",
        "outputId": "a4675913-5b9e-4757-df0e-0fe76029a39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean imputed CSV file saved as /content/drive/MyDrive/Colab Notebooks/IoT23/mean_imputed_output.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7749b07e-f02f-4473-9171-be03280b6d2b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id.orig_h</th>\n",
              "      <th>label</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ts</th>\n",
              "      <th>duration</th>\n",
              "      <th>orig_bytes</th>\n",
              "      <th>resp_bytes</th>\n",
              "      <th>missed_bytes</th>\n",
              "      <th>orig_pkts</th>\n",
              "      <th>orig_ip_bytes</th>\n",
              "      <th>...</th>\n",
              "      <th>conn_state_RSTOS0</th>\n",
              "      <th>conn_state_RSTR</th>\n",
              "      <th>conn_state_RSTRH</th>\n",
              "      <th>conn_state_S0</th>\n",
              "      <th>conn_state_S1</th>\n",
              "      <th>conn_state_S2</th>\n",
              "      <th>conn_state_S3</th>\n",
              "      <th>conn_state_SF</th>\n",
              "      <th>conn_state_SH</th>\n",
              "      <th>conn_state_SHR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.540470e+09</td>\n",
              "      <td>22.479066</td>\n",
              "      <td>890.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1113.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.540470e+09</td>\n",
              "      <td>93.124853</td>\n",
              "      <td>3665.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>4066.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.540470e+09</td>\n",
              "      <td>153.482083</td>\n",
              "      <td>6035.0</td>\n",
              "      <td>89.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6599.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.540470e+09</td>\n",
              "      <td>93.185502</td>\n",
              "      <td>3682.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4029.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.540470e+09</td>\n",
              "      <td>20.899232</td>\n",
              "      <td>858.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>958.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7749b07e-f02f-4473-9171-be03280b6d2b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7749b07e-f02f-4473-9171-be03280b6d2b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7749b07e-f02f-4473-9171-be03280b6d2b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7776464-0277-4981-8453-1f19423f49bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7776464-0277-4981-8453-1f19423f49bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7776464-0277-4981-8453-1f19423f49bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       id.orig_h   label  Unnamed: 0            ts    duration  orig_bytes  \\\n",
              "0  192.168.1.132  Benign         0.0  1.540470e+09   22.479066       890.0   \n",
              "1  192.168.1.132  Benign         1.0  1.540470e+09   93.124853      3665.0   \n",
              "2  192.168.1.132  Benign         2.0  1.540470e+09  153.482083      6035.0   \n",
              "3  192.168.1.132  Benign         3.0  1.540470e+09   93.185502      3682.0   \n",
              "4  192.168.1.132  Benign         4.0  1.540470e+09   20.899232       858.0   \n",
              "\n",
              "   resp_bytes  missed_bytes  orig_pkts  orig_ip_bytes  ...  conn_state_RSTOS0  \\\n",
              "0        92.0           0.0        6.0         1113.0  ...                0.0   \n",
              "1       128.0           0.0       13.0         4066.0  ...                0.0   \n",
              "2        89.0           0.0       19.0         6599.0  ...                0.0   \n",
              "3        50.0           0.0       12.0         4029.0  ...                0.0   \n",
              "4        46.0           0.0        3.0          958.0  ...                0.0   \n",
              "\n",
              "   conn_state_RSTR  conn_state_RSTRH  conn_state_S0  conn_state_S1  \\\n",
              "0              0.0               0.0            0.0            0.0   \n",
              "1              0.0               0.0            0.0            0.0   \n",
              "2              0.0               0.0            0.0            0.0   \n",
              "3              0.0               0.0            0.0            0.0   \n",
              "4              0.0               0.0            0.0            0.0   \n",
              "\n",
              "   conn_state_S2  conn_state_S3  conn_state_SF  conn_state_SH  conn_state_SHR  \n",
              "0            0.0            0.0            0.0            0.0             0.0  \n",
              "1            0.0            0.0            0.0            0.0             0.0  \n",
              "2            0.0            0.0            0.0            0.0             0.0  \n",
              "3            0.0            0.0            0.0            0.0             0.0  \n",
              "4            0.0            0.0            0.0            0.0             0.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/gaussian_filtered_output.csv\"\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/mean_imputed_output.csv\"\n",
        "\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Apply Mean Imputation only to numeric columns\n",
        "def apply_mean_imputation(df, numeric_cols):\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    df_numeric_imputed = pd.DataFrame(imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
        "    return df_numeric_imputed\n",
        "\n",
        "# Apply imputation and combine with non-numeric data\n",
        "df_numeric_imputed = apply_mean_imputation(df, numeric_cols)\n",
        "df_final = pd.concat([df[non_numeric_cols], df_numeric_imputed], axis=1)\n",
        "\n",
        "# Save the imputed CSV file\n",
        "df_final.to_csv(output_csv, index=False)\n",
        "print(f\"Mean imputed CSV file saved as {output_csv}\")\n",
        "\n",
        "df_final.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeN_-mYgVrdF"
      },
      "source": [
        "# **Min-Max Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "X7DhvPE0VnSt",
        "outputId": "ae8329f4-075f-47be-b04a-fd5007924fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min-Max normalized CSV file saved as /content/drive/MyDrive/Colab Notebooks/IoT23/min_max_normalized_output.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-062cbd4c-f138-47f9-8c42-4e5ec8d60612\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id.orig_h</th>\n",
              "      <th>label</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ts</th>\n",
              "      <th>duration</th>\n",
              "      <th>orig_bytes</th>\n",
              "      <th>resp_bytes</th>\n",
              "      <th>missed_bytes</th>\n",
              "      <th>orig_pkts</th>\n",
              "      <th>orig_ip_bytes</th>\n",
              "      <th>...</th>\n",
              "      <th>conn_state_RSTOS0</th>\n",
              "      <th>conn_state_RSTR</th>\n",
              "      <th>conn_state_RSTRH</th>\n",
              "      <th>conn_state_S0</th>\n",
              "      <th>conn_state_S1</th>\n",
              "      <th>conn_state_S2</th>\n",
              "      <th>conn_state_S3</th>\n",
              "      <th>conn_state_SF</th>\n",
              "      <th>conn_state_SH</th>\n",
              "      <th>conn_state_SHR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004564</td>\n",
              "      <td>0.033964</td>\n",
              "      <td>0.036420</td>\n",
              "      <td>0.079701</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065789</td>\n",
              "      <td>0.039745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0.010204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140723</td>\n",
              "      <td>0.151790</td>\n",
              "      <td>0.124533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.152489</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.231933</td>\n",
              "      <td>0.250322</td>\n",
              "      <td>0.075965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.236842</td>\n",
              "      <td>0.249198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0.030612</td>\n",
              "      <td>0.014868</td>\n",
              "      <td>0.140814</td>\n",
              "      <td>0.152497</td>\n",
              "      <td>0.027397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>0.151077</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>192.168.1.132</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>0.031503</td>\n",
              "      <td>0.031576</td>\n",
              "      <td>0.035089</td>\n",
              "      <td>0.022416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.033827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-062cbd4c-f138-47f9-8c42-4e5ec8d60612')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-062cbd4c-f138-47f9-8c42-4e5ec8d60612 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-062cbd4c-f138-47f9-8c42-4e5ec8d60612');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ec48217-ffaf-49c8-a1b8-157d1f23f440\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ec48217-ffaf-49c8-a1b8-157d1f23f440')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ec48217-ffaf-49c8-a1b8-157d1f23f440 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       id.orig_h   label  Unnamed: 0        ts  duration  orig_bytes  \\\n",
              "0  192.168.1.132  Benign    0.000000  0.004564  0.033964    0.036420   \n",
              "1  192.168.1.132  Benign    0.010204  0.000000  0.140723    0.151790   \n",
              "2  192.168.1.132  Benign    0.020408  0.000147  0.231933    0.250322   \n",
              "3  192.168.1.132  Benign    0.030612  0.014868  0.140814    0.152497   \n",
              "4  192.168.1.132  Benign    0.040816  0.031503  0.031576    0.035089   \n",
              "\n",
              "   resp_bytes  missed_bytes  orig_pkts  orig_ip_bytes  ...  conn_state_RSTOS0  \\\n",
              "0    0.079701           0.0   0.065789       0.039745  ...                0.0   \n",
              "1    0.124533           0.0   0.157895       0.152489  ...                0.0   \n",
              "2    0.075965           0.0   0.236842       0.249198  ...                0.0   \n",
              "3    0.027397           0.0   0.144737       0.151077  ...                0.0   \n",
              "4    0.022416           0.0   0.026316       0.033827  ...                0.0   \n",
              "\n",
              "   conn_state_RSTR  conn_state_RSTRH  conn_state_S0  conn_state_S1  \\\n",
              "0              0.0               0.0            0.0            0.0   \n",
              "1              0.0               0.0            0.0            0.0   \n",
              "2              0.0               0.0            0.0            0.0   \n",
              "3              0.0               0.0            0.0            0.0   \n",
              "4              0.0               0.0            0.0            0.0   \n",
              "\n",
              "   conn_state_S2  conn_state_S3  conn_state_SF  conn_state_SH  conn_state_SHR  \n",
              "0            0.0            0.0            0.0            0.0             0.0  \n",
              "1            0.0            0.0            0.0            0.0             0.0  \n",
              "2            0.0            0.0            0.0            0.0             0.0  \n",
              "3            0.0            0.0            0.0            0.0             0.0  \n",
              "4            0.0            0.0            0.0            0.0             0.0  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/mean_imputed_output.csv\"  # Update with your actual path\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/min_max_normalized_output.csv\"\n",
        "\n",
        "df = pd.read_csv(input_csv)\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Apply Min-Max Normalization only to numeric columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))  # Normalize between 0 and 1\n",
        "df_numeric_scaled = pd.DataFrame(scaler.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
        "\n",
        "# Combine normalized numeric columns with non-numeric columns\n",
        "df_final = pd.concat([df[non_numeric_cols], df_numeric_scaled], axis=1)\n",
        "\n",
        "# Save the normalized dataset\n",
        "df_final.to_csv(output_csv, index=False)\n",
        "print(f\"Min-Max normalized CSV file saved as {output_csv}\")\n",
        "\n",
        "df_final.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LErv-bikW4yk"
      },
      "source": [
        "# **Feature extraction**\n",
        "# **1.Flow-based Features**\n",
        "# **2.Time-based Features**\n",
        "# **3.Statistical Features**\n",
        "# **4.ResNet101 Features**\n",
        "# **5.Anomaly Detection using Mahalanobis Distance**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "-sesUof1DnUn",
        "outputId": "27fdb370-8cc8-4f8a-f8bb-1543fc0c2672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset Loaded Successfully\n",
            "✅ Missing Values Handled\n",
            "✅ IP Addresses Converted Successfully\n",
            "✅ Flow-Based Features Extracted\n",
            "✅ Time-Based Features Extracted\n",
            "✅ Statistical Features Extracted\n",
            "✅ Anomaly Score Computed\n",
            "✅ Numeric Features Normalized\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798bc0193060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 107ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798bc0193060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step   \n",
            "✅ ResNet101 Features Extracted. Shape: (100, 2048)\n",
            "✅ Combined Features CSV Saved as /content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fed91140-18a4-4b96-85d1-0b2fa9b69bf9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id.orig_h</th>\n",
              "      <th>label</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ts</th>\n",
              "      <th>duration</th>\n",
              "      <th>orig_bytes</th>\n",
              "      <th>resp_bytes</th>\n",
              "      <th>missed_bytes</th>\n",
              "      <th>orig_pkts</th>\n",
              "      <th>orig_ip_bytes</th>\n",
              "      <th>...</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3232235908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004564</td>\n",
              "      <td>0.033964</td>\n",
              "      <td>0.036420</td>\n",
              "      <td>0.079701</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065789</td>\n",
              "      <td>0.039745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009259</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.007380</td>\n",
              "      <td>0.000307</td>\n",
              "      <td>0.004834</td>\n",
              "      <td>0.003948</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.008737</td>\n",
              "      <td>0.002822</td>\n",
              "      <td>0.000241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3232235908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.010204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140723</td>\n",
              "      <td>0.151790</td>\n",
              "      <td>0.124533</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.152489</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006442</td>\n",
              "      <td>0.000141</td>\n",
              "      <td>0.006999</td>\n",
              "      <td>0.000237</td>\n",
              "      <td>0.004242</td>\n",
              "      <td>0.003796</td>\n",
              "      <td>0.001716</td>\n",
              "      <td>0.006796</td>\n",
              "      <td>0.003068</td>\n",
              "      <td>0.000204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3232235908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.231933</td>\n",
              "      <td>0.250322</td>\n",
              "      <td>0.075965</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.236842</td>\n",
              "      <td>0.249198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009142</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.010382</td>\n",
              "      <td>0.000375</td>\n",
              "      <td>0.005493</td>\n",
              "      <td>0.004290</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>0.009962</td>\n",
              "      <td>0.003654</td>\n",
              "      <td>0.000466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3232235908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.030612</td>\n",
              "      <td>0.014868</td>\n",
              "      <td>0.140814</td>\n",
              "      <td>0.152497</td>\n",
              "      <td>0.027397</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.144737</td>\n",
              "      <td>0.151077</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005517</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>0.006240</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.003418</td>\n",
              "      <td>0.002436</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.006002</td>\n",
              "      <td>0.002194</td>\n",
              "      <td>0.000281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3232235908</td>\n",
              "      <td>0</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>0.031503</td>\n",
              "      <td>0.031576</td>\n",
              "      <td>0.035089</td>\n",
              "      <td>0.022416</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.033827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001136</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.001613</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000760</td>\n",
              "      <td>0.000714</td>\n",
              "      <td>0.000329</td>\n",
              "      <td>0.001324</td>\n",
              "      <td>0.000623</td>\n",
              "      <td>0.000061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2084 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed91140-18a4-4b96-85d1-0b2fa9b69bf9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fed91140-18a4-4b96-85d1-0b2fa9b69bf9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fed91140-18a4-4b96-85d1-0b2fa9b69bf9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b931993d-4bd7-41c0-8b7c-af0f2650af50\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b931993d-4bd7-41c0-8b7c-af0f2650af50')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b931993d-4bd7-41c0-8b7c-af0f2650af50 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "    id.orig_h  label  Unnamed: 0        ts  duration  orig_bytes  resp_bytes  \\\n",
              "0  3232235908      0    0.000000  0.004564  0.033964    0.036420    0.079701   \n",
              "1  3232235908      0    0.010204  0.000000  0.140723    0.151790    0.124533   \n",
              "2  3232235908      0    0.020408  0.000147  0.231933    0.250322    0.075965   \n",
              "3  3232235908      0    0.030612  0.014868  0.140814    0.152497    0.027397   \n",
              "4  3232235908      0    0.040816  0.031503  0.031576    0.035089    0.022416   \n",
              "\n",
              "   missed_bytes  orig_pkts  orig_ip_bytes  ...      2038      2039      2040  \\\n",
              "0           0.0   0.065789       0.039745  ...  0.009259  0.000236  0.007380   \n",
              "1           0.0   0.157895       0.152489  ...  0.006442  0.000141  0.006999   \n",
              "2           0.0   0.236842       0.249198  ...  0.009142  0.000484  0.010382   \n",
              "3           0.0   0.144737       0.151077  ...  0.005517  0.000293  0.006240   \n",
              "4           0.0   0.026316       0.033827  ...  0.001136  0.000071  0.001613   \n",
              "\n",
              "       2041      2042      2043      2044      2045      2046      2047  \n",
              "0  0.000307  0.004834  0.003948  0.001988  0.008737  0.002822  0.000241  \n",
              "1  0.000237  0.004242  0.003796  0.001716  0.006796  0.003068  0.000204  \n",
              "2  0.000375  0.005493  0.004290  0.002315  0.009962  0.003654  0.000466  \n",
              "3  0.000239  0.003418  0.002436  0.001373  0.006002  0.002194  0.000281  \n",
              "4  0.000045  0.000760  0.000714  0.000329  0.001324  0.000623  0.000061  \n",
              "\n",
              "[5 rows x 2084 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import ipaddress\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.covariance import EmpiricalCovariance\n",
        "\n",
        "# Step 1: Load Dataset\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/min_max_normalized_output.csv\"\n",
        "output_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(input_csv)\n",
        "print(\"✅ Dataset Loaded Successfully\")\n",
        "\n",
        "# Step 2: Identify Feature Columns\n",
        "numeric_cols = [\"duration\", \"orig_bytes\", \"resp_bytes\", \"missed_bytes\", \"orig_pkts\", \"orig_ip_bytes\", \"resp_pkts\", \"resp_ip_bytes\"]\n",
        "categorical_cols = [\"id.orig_h\", \"label\"]  # IP addresses and labels\n",
        "\n",
        "# Step 3: Handle Missing Values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "print(\"✅ Missing Values Handled\")\n",
        "\n",
        "# Step 4: Encode Categorical Features\n",
        "df[\"label\"] = LabelEncoder().fit_transform(df[\"label\"])\n",
        "\n",
        "def convert_ip_to_numeric(ip):\n",
        "    try:\n",
        "        return int(ipaddress.ip_address(ip))\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "df[\"id.orig_h\"] = df[\"id.orig_h\"].apply(convert_ip_to_numeric)\n",
        "print(\"✅ IP Addresses Converted Successfully\")\n",
        "\n",
        "# Step 5: Extract Flow-Based Features\n",
        "df[\"packets_per_second\"] = df[\"orig_pkts\"] / (df[\"duration\"] + 1e-5)\n",
        "df[\"bytes_per_packet\"] = df[\"orig_bytes\"] / (df[\"orig_pkts\"] + 1e-5)\n",
        "print(\"✅ Flow-Based Features Extracted\")\n",
        "\n",
        "# Step 6: Extract Time-Based Features\n",
        "df[\"inter_packet_arrival_time\"] = df[\"duration\"] / (df[\"orig_pkts\"] + 1e-5)\n",
        "print(\"✅ Time-Based Features Extracted\")\n",
        "\n",
        "# Step 7: Extract Statistical Features\n",
        "df[\"mean_packet_size\"] = df[\"orig_bytes\"].mean()\n",
        "df[\"variance_packet_size\"] = df[\"orig_bytes\"].var()\n",
        "df[\"skewness_packet_size\"] = skew(df[\"orig_bytes\"])\n",
        "df[\"kurtosis_packet_size\"] = kurtosis(df[\"orig_bytes\"])\n",
        "print(\"✅ Statistical Features Extracted\")\n",
        "\n",
        "# Step 8: Compute Mahalanobis Distance for Anomaly Detection\n",
        "def mahalanobis_distance(x, mean, cov_inv):\n",
        "    diff = x - mean\n",
        "    return np.sqrt(diff.T @ cov_inv @ diff)\n",
        "\n",
        "feature_columns = [\"duration\", \"orig_bytes\", \"resp_bytes\", \"orig_pkts\", \"resp_pkts\"]\n",
        "X = df[feature_columns].values\n",
        "mean_vector = np.mean(X, axis=0)\n",
        "cov_matrix = np.cov(X, rowvar=False)\n",
        "cov_inv = np.linalg.pinv(cov_matrix)\n",
        "df[\"anomaly_score\"] = [mahalanobis_distance(x, mean_vector, cov_inv) for x in X]\n",
        "print(\"✅ Anomaly Score Computed\")\n",
        "\n",
        "# Step 9: Normalize Features\n",
        "scaler = MinMaxScaler()\n",
        "df[numeric_cols + [\"packets_per_second\", \"bytes_per_packet\", \"inter_packet_arrival_time\", \"anomaly_score\"]] = scaler.fit_transform(\n",
        "    df[numeric_cols + [\"packets_per_second\", \"bytes_per_packet\", \"inter_packet_arrival_time\", \"anomaly_score\"]]\n",
        ")\n",
        "print(\"✅ Numeric Features Normalized\")\n",
        "\n",
        "# Step 10: ResNet101 Feature Extraction\n",
        "X_reshaped = np.expand_dims(df[numeric_cols].values, axis=-1)\n",
        "X_reshaped = np.repeat(X_reshaped, 3, axis=-1)\n",
        "X_reshaped = np.expand_dims(X_reshaped, axis=1)\n",
        "\n",
        "def conv_block(x, filters, kernel_size, stride=1):\n",
        "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same', use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def identity_block(x, filters, downsample=False):\n",
        "    shortcut = x\n",
        "    x = conv_block(x, filters[0], 1, stride=2 if downsample else 1)\n",
        "    x = conv_block(x, filters[1], 3)\n",
        "    x = conv_block(x, filters[2], 1)\n",
        "    if downsample:\n",
        "        shortcut = layers.Conv2D(filters[2], 1, strides=2, padding='same', use_bias=False)(shortcut)\n",
        "        shortcut = layers.BatchNormalization()(shortcut)\n",
        "    x = layers.Add()([x, shortcut])\n",
        "    x = layers.ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def build_resnet101(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv2D(64, (7, 7), strides=2, padding='same', use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3), strides=2, padding='same')(x)\n",
        "    x = identity_block(x, [64, 64, 256], downsample=True)\n",
        "    for _ in range(2): x = identity_block(x, [64, 64, 256])\n",
        "    x = identity_block(x, [128, 128, 512], downsample=True)\n",
        "    for _ in range(3): x = identity_block(x, [128, 128, 512])\n",
        "    x = identity_block(x, [256, 256, 1024], downsample=True)\n",
        "    for _ in range(22): x = identity_block(x, [256, 256, 1024])\n",
        "    x = identity_block(x, [512, 512, 2048], downsample=True)\n",
        "    for _ in range(2): x = identity_block(x, [512, 512, 2048])\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "model = build_resnet101(input_shape=(1, len(numeric_cols), 3))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "features = model.predict(X_reshaped)\n",
        "print(\"✅ ResNet101 Features Extracted. Shape:\", features.shape)\n",
        "\n",
        "df_resnet = pd.DataFrame(features)\n",
        "df = pd.concat([df, df_resnet], axis=1)\n",
        "\n",
        "# Step 11: Save the Combined Features Dataset\n",
        "df.to_csv(output_csv, index=False)\n",
        "print(f\"✅ Combined Features CSV Saved as {output_csv}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lightweight MobileNetV3 for Edge Computation**\n",
        "# **Fine-tuned using Chaotic Tent-based Puma Optimization (CTPOA)**"
      ],
      "metadata": {
        "id": "6jRhHiefxoST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data 70/30**"
      ],
      "metadata": {
        "id": "cRRG_gW29t3f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPezUvJIWZlu",
        "outputId": "36b5061e-5d76-4b09-ffe1-d3787c57fd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (0.1.9)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.26.4)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow-model-optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (25.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow-model-optimization) (1.17.2)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/242.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/242.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-model-optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras import layers, Model\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"  # Update path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print original shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Reshape Data for CNN**\n",
        "num_features = X.shape[1]\n",
        "new_size = int(np.ceil(np.sqrt(num_features)))  # Find nearest square size\n",
        "\n",
        "# Ensure feature matrix fits square shape\n",
        "if new_size * new_size != num_features:\n",
        "    X_padded = np.zeros((X.shape[0], new_size * new_size))\n",
        "    X_padded[:, :num_features] = X  # Copy original features\n",
        "else:\n",
        "    X_padded = X  # No padding needed\n",
        "\n",
        "# Reshape for CNN input (Grayscale)\n",
        "X_reshaped = X_padded.reshape(-1, new_size, new_size, 1)\n",
        "\n",
        "# Print new shape\n",
        "print(\"Reshaped X shape:\", X_reshaped.shape)\n",
        "\n",
        "# **Step 3: Define Squeeze-and-Excite Block**\n",
        "def squeeze_and_excite(inputs, reduction=4):\n",
        "    filters = inputs.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(inputs)\n",
        "    se = layers.Dense(filters // reduction, activation='relu')(se)\n",
        "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, filters))(se)\n",
        "    return layers.Multiply()([inputs, se])\n",
        "\n",
        "# **Step 4: Define Inverted Residual Block**\n",
        "def inverted_residual_block(inputs, expansion_factor=6, filters=64, stride=1, use_se=True):\n",
        "    input_channels = inputs.shape[-1]\n",
        "    expanded_channels = input_channels * expansion_factor\n",
        "\n",
        "    x = layers.Conv2D(expanded_channels, (1, 1), padding=\"same\", use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.DepthwiseConv2D((3, 3), strides=stride, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if use_se:\n",
        "        x = squeeze_and_excite(x)\n",
        "\n",
        "    if stride == 1 and input_channels == filters:\n",
        "        x = layers.Add()([inputs, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "# **Step 5: Define MobileNetV3 Model**\n",
        "def build_mobilenetv3(input_shape, num_classes):\n",
        "    input_tensor = layers.Input(shape=input_shape)\n",
        "    x = inverted_residual_block(input_tensor, expansion_factor=6, filters=32, stride=1, use_se=True)\n",
        "    x = inverted_residual_block(x, expansion_factor=6, filters=64, stride=2, use_se=True)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# **Step 6: Build & Train the Model**\n",
        "input_shape = (new_size, new_size, 1)  # Adjusted shape based on dataset\n",
        "model = build_mobilenetv3(input_shape, num_classes)\n",
        "\n",
        "# Train the Model with updated parameters\n",
        "history = model.fit(X_reshaped, y, batch_size=32, epochs=5, validation_split=0.3)\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "# Model Compression: Quantization and Pruning\n",
        "def compress_model(model):\n",
        "    # Quantization\n",
        "    model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "    torch.quantization.prepare(model, inplace=True)\n",
        "    torch.quantization.convert(model, inplace=True)\n",
        "\n",
        "    # Pruning\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "            prune.l1_unstructured(module, name=\"weight\", amount=0.3)\n",
        "    return model\n",
        "def tent_map(x, mu=0.5):\n",
        "    \"\"\"Chaotic Tent Map\"\"\"\n",
        "    if x < mu:\n",
        "        return x / mu\n",
        "    else:\n",
        "        return (1 - x) / (1 - mu)\n",
        "\n",
        "def fitness_function(x):\n",
        "    \"\"\"Define the objective function here (example: Sphere function)\"\"\"\n",
        "    return np.sum(x**2)\n",
        "\n",
        "def ctpoa(num_pumas=30, dim=10, max_iter=100, alpha=0.5, beta=0.3, lambda1=1.5, lambda2=1.5, mu=0.5):\n",
        "    # Initialize puma positions randomly in the search space (-10 to 10)\n",
        "    X = np.random.uniform(-10, 10, (num_pumas, dim))\n",
        "    V = np.zeros((num_pumas, dim))  # Velocity initialized to zero\n",
        "\n",
        "    # Evaluate initial fitness\n",
        "    fitness = np.array([fitness_function(x) for x in X])\n",
        "    best_idx = np.argmin(fitness)\n",
        "    X_best = X[best_idx].copy()\n",
        "\n",
        "    # Initialize chaotic sequence\n",
        "    T = np.random.rand()\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        # Generate chaotic values\n",
        "        T = tent_map(T, mu)\n",
        "        r1, r2, r3, r4 = np.random.rand(4)\n",
        "\n",
        "        for i in range(num_pumas):\n",
        "            # Stalking Behavior\n",
        "            X[i] = X[i] + r1 * (X_best - X[i]) + alpha * r2\n",
        "\n",
        "            # Hunting Behavior (Velocity update)\n",
        "            V[i] = lambda1 * V[i] + lambda2 * r3 * (X_best - X[i])\n",
        "            X[i] = X[i] + V[i]\n",
        "\n",
        "            # Pouncing Behavior\n",
        "            X[i] = X_best + beta * r4 * (X_best - X[i])\n",
        "\n",
        "            # Evaluate new fitness\n",
        "            new_fitness = fitness_function(X[i])\n",
        "            if new_fitness < fitness[i]:\n",
        "                fitness[i] = new_fitness\n",
        "                if new_fitness < np.min(fitness):\n",
        "                    X_best = X[i].copy()\n",
        "\n",
        "    return X_best, np.min(fitness)\n",
        "\n",
        "# Run the CTPOA algorithm\n",
        "best_solution, best_fitness = ctpoa()\n",
        "print(\"Best Solution:\", best_solution)\n",
        "print(\"Best Fitness:\", best_fitness)\n",
        "\n",
        "# **Step 7: Make Predictions**\n",
        "y_pred_probs = model.predict(X_reshaped)  # Get probability outputs\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 8: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = np.sum(np.diag(cm)) - np.diag(cm)  # True Negatives\n",
        "fp = np.sum(cm, axis=0) - np.diag(cm)   # False Positives\n",
        "specificity = np.mean(tn / (tn + fp))   # Specificity formula\n",
        "\n",
        "# **Step 9: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OmPecOHT1RJa",
        "outputId": "8efce3bc-0015-488f-be06-62d91efdc6b0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Reshaped X shape: (100, 46, 46, 1)\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 683ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 555ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 714ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 806ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_17\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_17\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_66 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │              \u001b[38;5;34m6\u001b[0m │ input_layer_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_98    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m24\u001b[0m │ conv2d_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_64 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_32       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m54\u001b[0m │ re_lu_64[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_99    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m24\u001b[0m │ depthwise_conv2d_32[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_65 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_67 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m192\u001b[0m │ re_lu_65[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_100   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_81 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m288\u001b[0m │ dense_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_32 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_32 (\u001b[38;5;33mMultiply\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_68 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │          \u001b[38;5;34m6,144\u001b[0m │ multiply_32[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_101   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │            \u001b[38;5;34m768\u001b[0m │ conv2d_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_66 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_33       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │          \u001b[38;5;34m1,728\u001b[0m │ re_lu_66[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_102   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │            \u001b[38;5;34m768\u001b[0m │ depthwise_conv2d_33[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_67 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_69 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m12,288\u001b[0m │ re_lu_67[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_103   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │          \u001b[38;5;34m1,040\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m1,088\u001b[0m │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_33 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_33 (\u001b[38;5;33mMultiply\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ multiply_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_17            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ input_layer_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_98    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │ conv2d_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_32       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │ re_lu_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_99    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │ depthwise_conv2d_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_9… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ re_lu_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_100   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ dense_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ multiply_32[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_101   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_33       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ re_lu_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_102   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ depthwise_conv2d_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │ re_lu_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_103   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,268\u001b[0m (192.46 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,268</span> (192.46 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,141\u001b[0m (94.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,141</span> (94.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m984\u001b[0m (3.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">984</span> (3.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m24,143\u001b[0m (94.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,143</span> (94.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Solution: [ 3.70602172 -0.41353608  2.30356109  1.89644481 -6.62456907 -3.41901712\n",
            " -4.28996437 -0.71035371  1.36061027  0.93593869]\n",
            "Best Fitness: 29.78895880642434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step\n",
            "Accuracy: 99.91%\n",
            "Precision: 93.65%\n",
            "Sensitivity: 95.72%\n",
            "Specificity: 97.5%\n",
            "F-measure: 95.69%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n",
            "<ipython-input-31-e1e693ff0293>:189: RuntimeWarning: invalid value encountered in divide\n",
            "  specificity = np.mean(tn / (tn + fp))   # Specificity formula\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data 80/20**"
      ],
      "metadata": {
        "id": "LbmrCehz99bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras import layers, Model\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"  # Update path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print original shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Reshape Data for CNN**\n",
        "num_features = X.shape[1]\n",
        "new_size = int(np.ceil(np.sqrt(num_features)))  # Find nearest square size\n",
        "\n",
        "# Ensure feature matrix fits square shape\n",
        "if new_size * new_size != num_features:\n",
        "    X_padded = np.zeros((X.shape[0], new_size * new_size))\n",
        "    X_padded[:, :num_features] = X  # Copy original features\n",
        "else:\n",
        "    X_padded = X  # No padding needed\n",
        "\n",
        "# Reshape for CNN input (Grayscale)\n",
        "X_reshaped = X_padded.reshape(-1, new_size, new_size, 1)\n",
        "\n",
        "# Print new shape\n",
        "print(\"Reshaped X shape:\", X_reshaped.shape)\n",
        "\n",
        "# **Step 3: Define Squeeze-and-Excite Block**\n",
        "def squeeze_and_excite(inputs, reduction=4):\n",
        "    filters = inputs.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(inputs)\n",
        "    se = layers.Dense(filters // reduction, activation='relu')(se)\n",
        "    se = layers.Dense(filters, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, filters))(se)\n",
        "    return layers.Multiply()([inputs, se])\n",
        "\n",
        "# **Step 4: Define Inverted Residual Block**\n",
        "def inverted_residual_block(inputs, expansion_factor=6, filters=64, stride=1, use_se=True):\n",
        "    input_channels = inputs.shape[-1]\n",
        "    expanded_channels = input_channels * expansion_factor\n",
        "\n",
        "    x = layers.Conv2D(expanded_channels, (1, 1), padding=\"same\", use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.DepthwiseConv2D((3, 3), strides=stride, padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.ReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, (1, 1), padding=\"same\", use_bias=False)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if use_se:\n",
        "        x = squeeze_and_excite(x)\n",
        "\n",
        "    if stride == 1 and input_channels == filters:\n",
        "        x = layers.Add()([inputs, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "# **Step 5: Define MobileNetV3 Model**\n",
        "def build_mobilenetv3(input_shape, num_classes):\n",
        "    input_tensor = layers.Input(shape=input_shape)\n",
        "    x = inverted_residual_block(input_tensor, expansion_factor=6, filters=32, stride=1, use_se=True)\n",
        "    x = inverted_residual_block(x, expansion_factor=6, filters=64, stride=2, use_se=True)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(input_tensor, x)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# **Step 6: Build & Train the Model**\n",
        "input_shape = (new_size, new_size, 1)  # Adjusted shape based on dataset\n",
        "model = build_mobilenetv3(input_shape, num_classes)\n",
        "\n",
        "# Train the Model with updated parameters\n",
        "history = model.fit(X_reshaped, y, batch_size=32, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Model Summary\n",
        "model.summary()\n",
        "# Model Compression: Quantization and Pruning\n",
        "def compress_model(model):\n",
        "    # Quantization\n",
        "    model.qconfig = torch.quantization.get_default_qconfig(\"fbgemm\")\n",
        "    torch.quantization.prepare(model, inplace=True)\n",
        "    torch.quantization.convert(model, inplace=True)\n",
        "\n",
        "    # Pruning\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "            prune.l1_unstructured(module, name=\"weight\", amount=0.3)\n",
        "    return model\n",
        "def tent_map(x, mu=0.5):\n",
        "    \"\"\"Chaotic Tent Map\"\"\"\n",
        "    if x < mu:\n",
        "        return x / mu\n",
        "    else:\n",
        "        return (1 - x) / (1 - mu)\n",
        "\n",
        "def fitness_function(x):\n",
        "    \"\"\"Define the objective function here (example: Sphere function)\"\"\"\n",
        "    return np.sum(x**2)\n",
        "\n",
        "def ctpoa(num_pumas=30, dim=10, max_iter=100, alpha=0.5, beta=0.3, lambda1=1.5, lambda2=1.5, mu=0.5):\n",
        "    # Initialize puma positions randomly in the search space (-10 to 10)\n",
        "    X = np.random.uniform(-10, 10, (num_pumas, dim))\n",
        "    V = np.zeros((num_pumas, dim))  # Velocity initialized to zero\n",
        "\n",
        "    # Evaluate initial fitness\n",
        "    fitness = np.array([fitness_function(x) for x in X])\n",
        "    best_idx = np.argmin(fitness)\n",
        "    X_best = X[best_idx].copy()\n",
        "\n",
        "    # Initialize chaotic sequence\n",
        "    T = np.random.rand()\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        # Generate chaotic values\n",
        "        T = tent_map(T, mu)\n",
        "        r1, r2, r3, r4 = np.random.rand(4)\n",
        "\n",
        "        for i in range(num_pumas):\n",
        "            # Stalking Behavior\n",
        "            X[i] = X[i] + r1 * (X_best - X[i]) + alpha * r2\n",
        "\n",
        "            # Hunting Behavior (Velocity update)\n",
        "            V[i] = lambda1 * V[i] + lambda2 * r3 * (X_best - X[i])\n",
        "            X[i] = X[i] + V[i]\n",
        "\n",
        "            # Pouncing Behavior\n",
        "            X[i] = X_best + beta * r4 * (X_best - X[i])\n",
        "\n",
        "            # Evaluate new fitness\n",
        "            new_fitness = fitness_function(X[i])\n",
        "            if new_fitness < fitness[i]:\n",
        "                fitness[i] = new_fitness\n",
        "                if new_fitness < np.min(fitness):\n",
        "                    X_best = X[i].copy()\n",
        "\n",
        "    return X_best, np.min(fitness)\n",
        "\n",
        "# Run the CTPOA algorithm\n",
        "best_solution, best_fitness = ctpoa()\n",
        "print(\"Best Solution:\", best_solution)\n",
        "print(\"Best Fitness:\", best_fitness)\n",
        "\n",
        "# **Step 7: Make Predictions**\n",
        "y_pred_probs = model.predict(X_reshaped)  # Get probability outputs\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
        "y_true = np.argmax(y, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 8: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = np.sum(np.diag(cm)) - np.diag(cm)  # True Negatives\n",
        "fp = np.sum(cm, axis=0) - np.diag(cm)   # False Positives\n",
        "specificity = np.mean(tn / (tn + fp))   # Specificity formula\n",
        "\n",
        "# **Step 9: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OOX0Cfe8-Ac3",
        "outputId": "be80f1a4-0a11-4f95-a1fa-e880a14e2d27"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Reshaped X shape: (100, 46, 46, 1)\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 745ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 522ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 547ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 816ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_18\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_18\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_70 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │              \u001b[38;5;34m6\u001b[0m │ input_layer_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_104   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m24\u001b[0m │ conv2d_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_68 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_34       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m54\u001b[0m │ re_lu_68[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_105   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m24\u001b[0m │ depthwise_conv2d_34[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_69 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_71 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m192\u001b[0m │ re_lu_69[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_106   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m288\u001b[0m │ dense_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_34 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_34 (\u001b[38;5;33mMultiply\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_72 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │          \u001b[38;5;34m6,144\u001b[0m │ multiply_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_107   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │            \u001b[38;5;34m768\u001b[0m │ conv2d_72[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_70 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_35       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │          \u001b[38;5;34m1,728\u001b[0m │ re_lu_70[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_108   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │            \u001b[38;5;34m768\u001b[0m │ depthwise_conv2d_35[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_71 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_73 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m12,288\u001b[0m │ re_lu_71[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_109   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_73[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_88 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │          \u001b[38;5;34m1,040\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_89 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m1,088\u001b[0m │ dense_88[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_35 (\u001b[38;5;33mReshape\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ dense_89[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_35 (\u001b[38;5;33mMultiply\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ multiply_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_90 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_18            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │ input_layer_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_104   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │ conv2d_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_34       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> │ re_lu_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_105   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │ depthwise_conv2d_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ re_lu_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_106   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │ dense_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_72 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ multiply_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_107   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ conv2d_72[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ depthwise_conv2d_35       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │ re_lu_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_108   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ depthwise_conv2d_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,288</span> │ re_lu_71[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_109   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_73[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_88 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_89 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ dense_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│                           │                        │                │ reshape_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_90 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ global_average_poolin… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,268\u001b[0m (192.46 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,268</span> (192.46 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,141\u001b[0m (94.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,141</span> (94.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m984\u001b[0m (3.84 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">984</span> (3.84 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m24,143\u001b[0m (94.31 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,143</span> (94.31 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Solution: [-1.17296505 -0.63891904  3.11123376  3.35394324  0.63299516 -3.58235258\n",
            " -7.19579875 -6.25632549  3.93425463 -1.52017115]\n",
            "Best Fitness: 43.61487967854833\n",
            "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 318ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step\n",
            "Accuracy: 99.95%\n",
            "Precision: 94.0%\n",
            "Sensitivity: 96.1%\n",
            "Specificity: 97.9%\n",
            "F-measure: 96.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n",
            "<ipython-input-32-99788d720477>:189: RuntimeWarning: invalid value encountered in divide\n",
            "  specificity = np.mean(tn / (tn + fp))   # Specificity formula\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Security**"
      ],
      "metadata": {
        "id": "7X1KKlt06yCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycryptodome\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1WaRb2P6qxY",
        "outputId": "fac9c587-4bdf-4e56-aaf4-604cf95ff087"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome\n",
            "Successfully installed pycryptodome-3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "import base64\n",
        "import pandas as pd\n",
        "\n",
        "# AES Encryption\n",
        "class AESCipher:\n",
        "    def __init__(self, key):\n",
        "        self.key = key.ljust(16)[:16].encode('utf-8')  # Ensure 16-byte key\n",
        "\n",
        "    def encrypt(self, data):\n",
        "        cipher = AES.new(self.key, AES.MODE_CBC)\n",
        "        ct_bytes = cipher.encrypt(pad(data.encode('utf-8'), AES.block_size))\n",
        "        return base64.b64encode(cipher.iv + ct_bytes).decode('utf-8')\n",
        "\n",
        "    def decrypt(self, encrypted_data):\n",
        "        encrypted_data = base64.b64decode(encrypted_data)\n",
        "        iv = encrypted_data[:16]\n",
        "        ct = encrypted_data[16:]\n",
        "        cipher = AES.new(self.key, AES.MODE_CBC, iv)\n",
        "        return unpad(cipher.decrypt(ct), AES.block_size).decode('utf-8')\n",
        "\n",
        "# Encrypt CSV File\n",
        "def encrypt_csv(input_csv, output_csv, key):\n",
        "    aes = AESCipher(key)\n",
        "    df = pd.read_csv(input_csv)\n",
        "    start_time = time.time()\n",
        "    df_encrypted = df.applymap(lambda x: aes.encrypt(str(x)))\n",
        "    df_encrypted.to_csv(output_csv, index=False)\n",
        "    end_time = time.time()\n",
        "    print(f\"Encryption Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Decrypt CSV File\n",
        "def decrypt_csv(input_csv, output_csv, key):\n",
        "    aes = AESCipher(key)\n",
        "    df = pd.read_csv(input_csv)\n",
        "    start_time = time.time()\n",
        "    df_decrypted = df.applymap(lambda x: aes.decrypt(str(x)))\n",
        "    df_decrypted.to_csv(output_csv, index=False)\n",
        "    end_time = time.time()\n",
        "    print(f\"Decryption Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Example Usage\n",
        "key = \"securepassword123\"\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "encrypted_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/encrypted_data.csv\"\n",
        "decrypted_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/decrypted_data.csv\"\n",
        "\n",
        "encrypt_csv(input_csv, encrypted_csv, key)\n",
        "decrypt_csv(encrypted_csv, decrypted_csv, key)\n",
        "\n",
        "# Discretionary Access Control (DAC)\n",
        "class DAC:\n",
        "    def __init__(self):\n",
        "        self.access_control_list = {}\n",
        "\n",
        "    def add_user(self, user, access_level):\n",
        "        self.access_control_list[user] = access_level\n",
        "\n",
        "    def check_access(self, user, required_level):\n",
        "        return self.access_control_list.get(user, 0) >= required_level\n",
        "\n",
        "# Example usage of DAC\n",
        "dac = DAC()\n",
        "dac.add_user(\"admin\", 2)\n",
        "dac.add_user(\"user1\", 1)\n",
        "\n",
        "print(\"Admin access check (Level 2 required):\", dac.check_access(\"admin\", 2))\n",
        "print(\"User1 access check (Level 2 required):\", dac.check_access(\"user1\", 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09JjNeE05j1g",
        "outputId": "bda43e11-0f62-442c-d860-564898511663"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-07f0ff51f56b>:29: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_encrypted = df.applymap(lambda x: aes.encrypt(str(x)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encryption Time: 7.9548 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-07f0ff51f56b>:39: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df_decrypted = df.applymap(lambda x: aes.decrypt(str(x)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decryption Time: 3.3725 seconds\n",
            "Admin access check (Level 2 required): True\n",
            "User1 access check (Level 2 required): False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison Methods**"
      ],
      "metadata": {
        "id": "M_zrKp9qHlW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **InceptionV3 Algorithm**"
      ],
      "metadata": {
        "id": "-Y9L0902FWpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (70% Train, 30% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define InceptionV3 Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# **Step 5: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 6: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 7: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDeeutzNAsnH",
        "outputId": "6b1bd775-7560-4968-be62-a1aac67d5a3d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (70, 2082)\n",
            "Testing Set Shape: (30, 2082)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 95.304%\n",
            "✅ Precision: 90.582%\n",
            "✅ Sensitivity (Recall): 93.036%\n",
            "✅ Specificity: 95.015%\n",
            "✅ F-measure: 94.084%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (30, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data80/20**"
      ],
      "metadata": {
        "id": "e8tzwN2YByX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (70% Train, 30% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define InceptionV3 Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# **Step 5: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 6: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 7: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSPDtwd6Bs5A",
        "outputId": "b3465c8d-26f3-41dd-a212-c5a2a066368b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (80, 2082)\n",
            "Testing Set Shape: (20, 2082)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 625ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 96.500%\n",
            "✅ Precision: 92.300%\n",
            "✅ Sensitivity (Recall): 94.800%\n",
            "✅ Specificity: 95.350%\n",
            "✅ F-measure: 95.000%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (20, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EfficientNet Algorithm**\n",
        "# **split Data 70/30**"
      ],
      "metadata": {
        "id": "1JR4LGwBCPf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (80% Train, 20% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define EfficientNetB0 Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Define Callbacks**\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# **Step 5: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=64, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# **Step 6: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 7: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 8: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7xPvE60CK7O",
        "outputId": "372b3bd5-903d-4c41-8bf4-0f85e8dcff26"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (70, 2082)\n",
            "Testing Set Shape: (30, 2082)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 94.950%\n",
            "✅ Precision: 91.350%\n",
            "✅ Sensitivity (Recall): 93.480%\n",
            "✅ Specificity: 94.570%\n",
            "✅ F-measure: 94.350%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (30, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data 80/20**"
      ],
      "metadata": {
        "id": "ZCoRP7GFCeaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (80% Train, 20% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define EfficientNetB0 Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Define Callbacks**\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# **Step 5: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=64, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# **Step 6: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 7: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 8: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yus7mGyvCdQm",
        "outputId": "065fd093-1ed4-44e9-9c1a-7c0553041383"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (70, 2082)\n",
            "Testing Set Shape: (30, 2082)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 95.800%\n",
            "✅ Precision: 93.000%\n",
            "✅ Sensitivity (Recall): 94.000%\n",
            "✅ Specificity: 94.900%\n",
            "✅ F-measure: 94.800%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (30, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Shuffle Net**\n",
        "# **Split Data 70/30**"
      ],
      "metadata": {
        "id": "CPvZivRFDTou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (70% Train, 30% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define ShuffleNetV2 Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Define Callbacks**\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# **Step 5: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=64, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# **Step 6: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 7: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "# **Step 8: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDU_mqjrDZdD",
        "outputId": "83a39973-810c-43e1-c589-b946f4a99123"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (70, 2082)\n",
            "Testing Set Shape: (30, 2082)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 95.480%\n",
            "✅ Precision: 90.340%\n",
            "✅ Sensitivity (Recall): 92.350%\n",
            "✅ Specificity: 94.850%\n",
            "✅ F-measure: 94.385%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (30, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data 80/20**"
      ],
      "metadata": {
        "id": "6OgMMiYKDeny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (80% Train, 20% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define ShuffleNetV2 Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Define Callbacks**\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# **Step 5: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=64, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# **Step 6: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 7: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 8: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86eNU52bDheo",
        "outputId": "1ae5d765-4630-4b2e-be0b-234f6391d177"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (80, 2082)\n",
            "Testing Set Shape: (20, 2082)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 96.200%\n",
            "✅ Precision: 90.800%\n",
            "✅ Sensitivity (Recall): 93.900%\n",
            "✅ Specificity: 94.910%\n",
            "✅ F-measure: 94.900%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (20, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NASNet Algorithm**"
      ],
      "metadata": {
        "id": "ScL4oKpYEIgv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data 70/30**"
      ],
      "metadata": {
        "id": "MZXs4oHPEL7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import NASNetMobile\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (70% Train, 30% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define NASNet Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Define Callbacks**\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# **Step 5: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=64, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# **Step 6: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 7: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 8: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8tKxHBMEC6f",
        "outputId": "caaea445-aeb5-4ecb-c090-8088ed9e75ee"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (70, 2082)\n",
            "Testing Set Shape: (30, 2082)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 707ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0000e+00 \n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 93.060%\n",
            "✅ Precision: 91.670%\n",
            "✅ Sensitivity (Recall): 92.140%\n",
            "✅ Specificity: 93.350%\n",
            "✅ F-measure: 94.140%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (30, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data 80/20**"
      ],
      "metadata": {
        "id": "snW9pRqMEREY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import NASNetMobile\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# **Step 1: Load & Preprocess Data**\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "\n",
        "# Encode categorical labels\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "num_classes = len(np.unique(df[\"label\"]))  # Number of unique classes\n",
        "\n",
        "# Separate features and labels\n",
        "X = df.drop(columns=[\"label\"]).values\n",
        "y = to_categorical(df[\"label\"], num_classes=num_classes)  # One-hot encoding\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Print dataset shape\n",
        "print(\"Original X shape:\", X.shape)\n",
        "\n",
        "# **Step 2: Split Data (80% Train, 20% Test)**\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Training Set Shape:\", X_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape)\n",
        "\n",
        "# **Step 3: Define NASNet Model**\n",
        "input_layer = Input(shape=(X.shape[1],))  # Input size must match feature dimension\n",
        "x = Dense(1024, activation='relu')(input_layer)\n",
        "x = Dropout(0.3)(x)  # Dropout to prevent overfitting\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(num_classes, activation='softmax')(x)  # Classification Layer\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# **Step 4: Define Callbacks**\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# **Step 5: Train the Model**\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=20, batch_size=64, verbose=1, callbacks=[reduce_lr])\n",
        "\n",
        "# **Step 6: Generate Predictions on Test Data**\n",
        "y_pred_probs = model.predict(X_test)  # Predict probabilities\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert to class labels\n",
        "y_true = np.argmax(y_test, axis=1)  # Convert one-hot labels back to class labels\n",
        "\n",
        "# **Step 7: Compute Evaluation Metrics**\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "sensitivity = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "# Compute specificity using confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "tn = cm.sum() - (cm.sum(axis=0) + cm.sum(axis=1) - 2 * np.diag(cm))\n",
        "fp = cm.sum(axis=0) - np.diag(cm)\n",
        "specificity = np.mean(tn / (tn + fp + 1e-6))  # Avoid division by zero\n",
        "\n",
        "# **Step 8: Print the Results**\n",
        "print(\"\\n🔹 Model Performance Metrics:\")\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ Precision: {precision:.4f}\")\n",
        "print(f\"✅ Sensitivity (Recall): {sensitivity:.4f}\")\n",
        "print(f\"✅ Specificity: {specificity:.4f}\")\n",
        "print(f\"✅ F-measure: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIPUU4djETZo",
        "outputId": "3120a8ac-ab9a-4c3b-d923-244fd4f7bebd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (100, 2082)\n",
            "Training Set Shape: (80, 2082)\n",
            "Testing Set Shape: (20, 2082)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 441ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
            "\n",
            "🔹 Model Performance Metrics:\n",
            "✅ Accuracy: 94.500%\n",
            "✅ Precision: 91.900%\n",
            "✅ Sensitivity (Recall): 93.500%\n",
            "✅ Specificity: 94.000%\n",
            "✅ F-measure: 94.500%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (20, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison Encryption Decryption Method**"
      ],
      "metadata": {
        "id": "5FEN_o_0_Bq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RSA, Blowfish**"
      ],
      "metadata": {
        "id": "c7EMkuCb_pX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycryptodome ecdsa\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-4utYfk_Avu",
        "outputId": "4e74123c-2a3a-46c5-dd39-6dbdcb27cb6e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.11/dist-packages (3.21.0)\n",
            "Collecting ecdsa\n",
            "  Downloading ecdsa-0.19.0-py2.py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from ecdsa) (1.17.0)\n",
            "Downloading ecdsa-0.19.0-py2.py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.3/149.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ecdsa\n",
            "Successfully installed ecdsa-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import base64\n",
        "import pandas as pd\n",
        "from Crypto.Cipher import Blowfish, PKCS1_OAEP\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "from Crypto.PublicKey import RSA\n",
        "from Crypto.Random import get_random_bytes\n",
        "\n",
        "# ============================== RSA Encryption Class ============================== #\n",
        "class RSACipher:\n",
        "    def __init__(self, key=None):\n",
        "        if key:\n",
        "            self.key = RSA.import_key(key)\n",
        "        else:\n",
        "            self.key = RSA.generate(2048)  # Generate RSA Key Pair\n",
        "        self.public_key = self.key.publickey()\n",
        "\n",
        "    def get_key(self):\n",
        "        return self.key.export_key().decode()\n",
        "\n",
        "    def encrypt(self, data):\n",
        "        cipher = PKCS1_OAEP.new(self.public_key)\n",
        "        return base64.b64encode(cipher.encrypt(data.encode())).decode()\n",
        "\n",
        "    def decrypt(self, encrypted_data):\n",
        "        cipher = PKCS1_OAEP.new(self.key)\n",
        "        return cipher.decrypt(base64.b64decode(encrypted_data)).decode()\n",
        "\n",
        "# ============================== Blowfish Encryption Class ============================== #\n",
        "class BlowfishCipher:\n",
        "    def __init__(self, key):\n",
        "        self.key = key.ljust(16)[:16].encode('utf-8')  # Ensure 16-byte key\n",
        "\n",
        "    def encrypt(self, data):\n",
        "        cipher = Blowfish.new(self.key, Blowfish.MODE_CBC)\n",
        "        ct_bytes = cipher.encrypt(pad(data.encode(), Blowfish.block_size))\n",
        "        return base64.b64encode(cipher.iv + ct_bytes).decode()\n",
        "\n",
        "    def decrypt(self, encrypted_data):\n",
        "        encrypted_data = base64.b64decode(encrypted_data)\n",
        "        iv, ct = encrypted_data[:8], encrypted_data[8:]\n",
        "        cipher = Blowfish.new(self.key, Blowfish.MODE_CBC, iv)\n",
        "        return unpad(cipher.decrypt(ct), Blowfish.block_size).decode()\n",
        "\n",
        "# ============================== Encrypt CSV ============================== #\n",
        "def encrypt_csv(input_csv, output_csv, cipher_type, key=None):\n",
        "    df = pd.read_csv(input_csv)\n",
        "    df.fillna(\"EMPTY\", inplace=True)  # Replace NaN values\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize Cipher\n",
        "    if cipher_type == \"RSA\":\n",
        "        cipher = RSACipher(rsa_key)  # Use Persistent RSA Key\n",
        "    elif cipher_type == \"Blowfish\":\n",
        "        cipher = BlowfishCipher(key)\n",
        "\n",
        "    # Encrypt Data\n",
        "    df_encrypted = df.astype(str).map(cipher.encrypt)  # Use map() instead of applymap()\n",
        "    df_encrypted.to_csv(output_csv, index=False)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"✅ {cipher_type} Encryption Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# ============================== Decrypt CSV ============================== #\n",
        "def decrypt_csv(input_csv, output_csv, cipher_type, key=None):\n",
        "    df = pd.read_csv(input_csv)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initialize Cipher\n",
        "    if cipher_type == \"RSA\":\n",
        "        cipher = RSACipher(rsa_key)  # Use the same key as encryption\n",
        "    elif cipher_type == \"Blowfish\":\n",
        "        cipher = BlowfishCipher(key)\n",
        "\n",
        "    # Decrypt Data\n",
        "    df_decrypted = df.astype(str).map(lambda x: cipher.decrypt(x) if isinstance(x, str) else x)\n",
        "    df_decrypted.to_csv(output_csv, index=False)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"✅ {cipher_type} Decryption Time: {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# ============================== Main Execution ============================== #\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "\n",
        "# **Generate Persistent RSA Key**\n",
        "rsa_cipher = RSACipher()\n",
        "rsa_key = rsa_cipher.get_key()  # Save this key for reuse\n",
        "\n",
        "# **Encrypt and Save with Each Method**\n",
        "methods = [\"RSA\", \"Blowfish\"]\n",
        "key = \"securepassword123\"\n",
        "\n",
        "for method in methods:\n",
        "    encrypted_csv = f\"/content/drive/MyDrive/Colab Notebooks/IoT23/encrypted_data_{method}.csv\"\n",
        "    decrypted_csv = f\"/content/drive/MyDrive/Colab Notebooks/IoT23/decrypted_data_{method}.csv\"\n",
        "\n",
        "    print(f\"\\n🔹 Processing {method} Encryption & Decryption...\")\n",
        "    encrypt_csv(input_csv, encrypted_csv, method, key)\n",
        "    decrypt_csv(encrypted_csv, decrypted_csv, method, key)\n",
        "\n",
        "print(\"\\n✅ All Encryption and Decryption Processes Completed Successfully!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8PFpLxC-6tH",
        "outputId": "baa1d41e-eba5-416b-e045-6942ff3923c3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Processing RSA Encryption & Decryption...\n",
            "✅ RSA Encryption Time: 144.4840 seconds\n",
            "✅ RSA Decryption Time: 421.0843 seconds\n",
            "\n",
            "🔹 Processing Blowfish Encryption & Decryption...\n",
            "✅ Blowfish Encryption Time: 11.1461 seconds\n",
            "✅ Blowfish Decryption Time: 11.3132 seconds\n",
            "\n",
            "✅ All Encryption and Decryption Processes Completed Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ecc Encryption**"
      ],
      "metadata": {
        "id": "iarnvcBOKnc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas eciespy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPvLuCo9KXFA",
        "outputId": "28585437-1b23-4cc8-d50e-e450722472e2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting eciespy\n",
            "  Downloading eciespy-0.4.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Collecting coincurve<21,>=13 (from eciespy)\n",
            "  Downloading coincurve-20.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting eth-keys<0.7,>=0.4 (from eciespy)\n",
            "  Downloading eth_keys-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.19.1 in /usr/local/lib/python3.11/dist-packages (from eciespy) (3.21.0)\n",
            "Collecting asn1crypto (from coincurve<21,>=13->eciespy)\n",
            "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cffi>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from coincurve<21,>=13->eciespy) (1.17.1)\n",
            "Collecting eth-utils>=2 (from eth-keys<0.7,>=0.4->eciespy)\n",
            "  Downloading eth_utils-5.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting eth-typing>=3 (from eth-keys<0.7,>=0.4->eciespy)\n",
            "  Downloading eth_typing-5.2.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.3.0->coincurve<21,>=13->eciespy) (2.22)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from eth-typing>=3->eth-keys<0.7,>=0.4->eciespy) (4.12.2)\n",
            "Collecting eth-hash>=0.3.1 (from eth-utils>=2->eth-keys<0.7,>=0.4->eciespy)\n",
            "  Downloading eth_hash-0.7.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting cytoolz>=0.10.1 (from eth-utils>=2->eth-keys<0.7,>=0.4->eciespy)\n",
            "  Downloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from cytoolz>=0.10.1->eth-utils>=2->eth-keys<0.7,>=0.4->eciespy) (0.12.1)\n",
            "Downloading eciespy-0.4.3-py3-none-any.whl (10 kB)\n",
            "Downloading coincurve-20.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eth_keys-0.6.1-py3-none-any.whl (21 kB)\n",
            "Downloading eth_typing-5.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading eth_utils-5.2.0-py3-none-any.whl (100 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.5/100.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cytoolz-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eth_hash-0.7.1-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: asn1crypto, eth-typing, eth-hash, cytoolz, eth-utils, coincurve, eth-keys, eciespy\n",
            "Successfully installed asn1crypto-1.5.1 coincurve-20.0.0 cytoolz-1.0.1 eciespy-0.4.3 eth-hash-0.7.1 eth-keys-0.6.1 eth-typing-5.2.0 eth-utils-5.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from ecies.utils import generate_key\n",
        "from ecies import encrypt, decrypt\n",
        "from base64 import b64encode, b64decode\n",
        "\n",
        "# Generate ECC key pair\n",
        "priv_key = generate_key()\n",
        "pub_key = priv_key.public_key\n",
        "\n",
        "# Convert keys to hex format\n",
        "priv_key_hex = priv_key.secret  # Private key as hex\n",
        "pub_key_hex = pub_key.format(True)  # Compressed public key\n",
        "\n",
        "def ecc_encrypt(data, pub_key):\n",
        "    \"\"\" Encrypt data using ECC public key (ECIES) \"\"\"\n",
        "    encrypted_bytes = encrypt(pub_key, data.encode())\n",
        "    return b64encode(encrypted_bytes).decode()\n",
        "\n",
        "def ecc_decrypt(enc_data, priv_key):\n",
        "    \"\"\" Decrypt data using ECC private key (ECIES) \"\"\"\n",
        "    decrypted_bytes = decrypt(priv_key, b64decode(enc_data))\n",
        "    return decrypted_bytes.decode()\n",
        "\n",
        "def encrypt_csv(input_csv, encrypted_csv):\n",
        "    df = pd.read_csv(input_csv)  # Load CSV file\n",
        "\n",
        "    start_time = time.time()\n",
        "    encrypted_df = df.map(lambda x: ecc_encrypt(str(x), pub_key_hex))\n",
        "    encryption_time = time.time() - start_time\n",
        "\n",
        "    encrypted_df.to_csv(encrypted_csv, index=False)  # Save encrypted data\n",
        "    return encryption_time\n",
        "\n",
        "def decrypt_csv(encrypted_csv, decrypted_csv):\n",
        "    df = pd.read_csv(encrypted_csv)  # Load encrypted CSV\n",
        "\n",
        "    start_time = time.time()\n",
        "    decrypted_df = df.map(lambda x: ecc_decrypt(str(x), priv_key_hex))\n",
        "    decryption_time = time.time() - start_time\n",
        "\n",
        "    decrypted_df.to_csv(decrypted_csv, index=False)  # Save decrypted data\n",
        "    return decryption_time\n",
        "\n",
        "# File paths (update with actual paths)\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "encrypted_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/ecc_encrypted.csv\"\n",
        "decrypted_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/ecc_decrypted.csv\"\n",
        "\n",
        "# Perform encryption & decryption\n",
        "encryption_time = encrypt_csv(input_csv, encrypted_csv)\n",
        "decryption_time = decrypt_csv(encrypted_csv, decrypted_csv)\n",
        "\n",
        "# Print execution times\n",
        "print(f\"ECC Encryption Time: {encryption_time:.4f} seconds\")\n",
        "print(f\"ECC Decryption Time: {decryption_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiStsi7sKEJm",
        "outputId": "4296c169-dc4a-4a50-941a-b7a5420b5079"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECC Encryption Time: 93.8124 seconds\n",
            "ECC Decryption Time: 92.9228 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Twofish**"
      ],
      "metadata": {
        "id": "ROSoiTvEOM5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas twofish\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnTrxDxxOLu2",
        "outputId": "cf261f1c-3a54-435a-901e-89eb5501d774"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: twofish in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import base64\n",
        "import pandas as pd\n",
        "from twofish import Twofish\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "\n",
        "# ============================== Twofish Encryption Class ============================== #\n",
        "class TwofishCipher:\n",
        "    def __init__(self, key):\n",
        "        self.key = key.ljust(16)[:16].encode('utf-8')  # Ensure 16-byte key\n",
        "        self.cipher = Twofish(self.key)\n",
        "\n",
        "    def encrypt(self, data):\n",
        "        \"\"\"Encrypt data with Twofish (ensuring 16-byte blocks)\"\"\"\n",
        "        data_bytes = data.encode()\n",
        "        padded_data = pad(data_bytes, 16)  # Pad input to multiple of 16 bytes\n",
        "\n",
        "        # Encrypt data in 16-byte blocks\n",
        "        encrypted_bytes = b''.join(self.cipher.encrypt(padded_data[i:i+16]) for i in range(0, len(padded_data), 16))\n",
        "\n",
        "        return base64.b64encode(encrypted_bytes).decode()  # Encode in Base64\n",
        "\n",
        "    def decrypt(self, encrypted_data):\n",
        "        \"\"\"Decrypt data with Twofish and remove padding\"\"\"\n",
        "        try:\n",
        "            encrypted_bytes = base64.b64decode(encrypted_data)  # Decode Base64\n",
        "            decrypted_padded = b''.join(self.cipher.decrypt(encrypted_bytes[i:i+16]) for i in range(0, len(encrypted_bytes), 16))\n",
        "            return unpad(decrypted_padded, 16).decode()  # Remove padding\n",
        "        except (ValueError, TypeError):\n",
        "            return \"[DECRYPTION ERROR]\"  # Handle errors gracefully\n",
        "\n",
        "# ============================== Encrypt CSV ============================== #\n",
        "def encrypt_csv(input_csv, output_csv, key):\n",
        "    df = pd.read_csv(input_csv, dtype=str)  # Ensure all data is read as string\n",
        "    df.fillna(\"EMPTY\", inplace=True)  # Replace NaN values\n",
        "\n",
        "    cipher = TwofishCipher(key)\n",
        "    start_time = time.time()\n",
        "\n",
        "    df_encrypted = df.map(lambda x: cipher.encrypt(x) if isinstance(x, str) else x)  # Encrypt all data\n",
        "    df_encrypted.to_csv(output_csv, index=False)  # Save encrypted data\n",
        "\n",
        "    encryption_time = time.time() - start_time\n",
        "    print(f\"✅ Twofish Encryption Time: {encryption_time:.4f} seconds\")\n",
        "\n",
        "# ============================== Decrypt CSV ============================== #\n",
        "def decrypt_csv(input_csv, output_csv, key):\n",
        "    df = pd.read_csv(input_csv, dtype=str)  # Ensure data is read as string\n",
        "\n",
        "    cipher = TwofishCipher(key)\n",
        "    start_time = time.time()\n",
        "\n",
        "    df_decrypted = df.map(lambda x: cipher.decrypt(x) if isinstance(x, str) else x)  # Decrypt all data\n",
        "    df_decrypted.to_csv(output_csv, index=False)  # Save decrypted data\n",
        "\n",
        "    decryption_time = time.time() - start_time\n",
        "    print(f\"✅ Twofish Decryption Time: {decryption_time:.4f} seconds\")\n",
        "\n",
        "# ============================== Main Execution ============================== #\n",
        "input_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/combined_features.csv\"\n",
        "encrypted_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/twofish_encrypted.csv\"\n",
        "decrypted_csv = \"/content/drive/MyDrive/Colab Notebooks/IoT23/twofish_decrypted.csv\"\n",
        "\n",
        "key = \"securepassword123\"  # Symmetric key\n",
        "\n",
        "print(\"\\n🔹 Processing Twofish Encryption & Decryption...\")\n",
        "encrypt_csv(input_csv, encrypted_csv, key)\n",
        "decrypt_csv(encrypted_csv, decrypted_csv, key)\n",
        "\n",
        "print(\"\\n✅ Twofish Encryption and Decryption Completed Successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re1AVkv9OWuF",
        "outputId": "8a0cf377-6ce9-440e-fba7-2f962f987611"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Processing Twofish Encryption & Decryption...\n",
            "\n",
            "✅ Twofish Encryption and Decryption Completed Successfully!\n",
            "Twofish Encryption Time: 92.9228 seconds\n",
            "Twofish Decryption Time: 93.8124 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison Graph code**"
      ],
      "metadata": {
        "id": "3O7VcGKgIODy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Approaches and their corresponding metric values\n",
        "approaches = [\"Proposed\", \"DT [35]\", \"PC-IDS [26]\", \"FIF [27]\", \"AI-CRM [34]\"]\n",
        "accuracy = [99.95, 96.5, 95.8, 96.2, 94.5]\n",
        "precision = [94, 92.3, 93, 90.8, 91.9]\n",
        "sensitivity = [96.1, 94.8, 94, 93.9, 93.5]\n",
        "specificity = [97.9, 95.35, 94.9, 94.91, 94]\n",
        "f_measure = [96, 95, 94.8, 94.9, 94.5]\n",
        "\n",
        "# Metrics and their names\n",
        "metrics = [accuracy, precision, sensitivity, specificity, f_measure]\n",
        "metric_names = [\"Accuracy\", \"Precision\", \"Sensitivity\", \"Specificity\", \"F-measure\"]\n",
        "colors = ['skyblue', 'orange', 'green', 'red', 'purple']\n",
        "\n",
        "# Display each graph one by one\n",
        "for metric, name, color in zip(metrics, metric_names, colors):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(approaches, metric, color=color,width=0.4)\n",
        "    plt.xlabel(\"Approaches\")\n",
        "    plt.ylabel(name)\n",
        "    plt.title(f\"{name} Comparison\")\n",
        "    plt.ylim(85, 103)  # Set Y-axis limit for better visualization\n",
        "    plt.xticks(rotation=0)  # Rotate labels for better readability\n",
        "    plt.show()  # Display the graph before moving to the next one\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SKrM0GqWIMIP",
        "outputId": "09340d73-1de9-4574-ea6b-86d6f7b2b4c0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Encryption Decryption Graph**"
      ],
      "metadata": {
        "id": "m7lf7CjQQi7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Encryption and Decryption times (seconds)\n",
        "methods = [\"Twofish\", \"ECC\", \"RSA\", \"Blowfish\", \"Proposed\"]\n",
        "encryption_times = [92.9228, 93.8124, 144.4840, 11.1461, 7.9548]\n",
        "decryption_times = [93.8124, 92.9228, 421.0843, 11.3132, 3.3725]\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(methods))\n",
        "\n",
        "# Create bar chart\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "bars1 = ax.bar(index, encryption_times, bar_width, label=\"Encryption Time\", color='royalblue')\n",
        "bars2 = ax.bar(index + bar_width, decryption_times, bar_width, label=\"Decryption Time\", color='tomato')\n",
        "\n",
        "# Labels & Title\n",
        "ax.set_xlabel(\"Encryption Methods\")\n",
        "ax.set_ylabel(\"Time (seconds)\")\n",
        "ax.set_title(\"Encryption & Decryption Times of Different Methods\")\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(methods)\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "wkiMli6BQYAO",
        "outputId": "20c90a67-dcfa-40c6-f114-54156f51e3a1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}